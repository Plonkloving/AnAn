---
layout: post
read_time: true
show_date: true
title: "XSS漏洞原理"
date: 2024-06-20
img: posts/20210228/MLLibrary.jpg
category: theory
author: 李妍
description: "XSS原理以及利用方式"
tags:漏洞挖掘
---
跨站脚本是指恶意攻击者往web页面中插入恶意代码，当用户浏览该页之时，嵌入的代码就会被执行，从而达到恶意攻击用户的目的

危害：钓鱼、网站挂马、身份盗用、盗取用户信息。垃圾信息发送、劫持用户web行为、xss蠕虫
本身对服务器没有直接危害，而是通过网站传播对用户危害
通常通过留言、电子邮件向用户发送含有恶意代码的url，当受害者在浏览器中打开该url的时候，恶意脚本会执行

xss的类型
1.反射型
2.存储型
3.DOM型

反射型xss：也叫做非持久型，攻击者将恶意脚本附加到url参数中，发送给受害者，服务端未经严格过滤而输出在用户浏览器中，导致浏览器执行代码数据。
原本网站中输入框提交之后
![image](https://github.com/Plonkloving/AnAn/assets/102906830/d1913336-94ff-4564-931d-4d11e67d5261)
这个时候就发现了如果name处被恶意执行了，那么就会被攻击
钓鱼常用

流程：
1.攻击者把带有恶意脚本代码参数的url地址发送给用户
2.用户点击此链接
3.服务器端获取请求参数并且直接使用，服务器反射回结果页面






存储型：也叫做持久型，存储型可以保存到数据库，在其他用户访问到这条数据时，这个代码会在访问用户的浏览器端执行。
也就是说，如果我在网站上写了恶意脚本，那么这段脚本就会被网站保存下来，当下一个用户打开这个页面的时候网站就会执行这句话
一般出现在留言的地方或者有输入框的地方
一个办法就是尝试输入然后提交看看有没有执行
这里面主要就是js的代码，建议把前端的js重点看一下


实战利用
1.盗取cookie
前提条件：目标网站没有使用http-only；受害者可以访问到接收端；获取到cookie后用户没有退出登录
http-only是加在cookies上的一个标识，用于告诉浏览器不要向客户端脚本或其他暴露cookie。丹尼在cookie上设置httponly标识后，浏览器就会知道这是特殊的cookie，只能由服务器检索，所有来自客户端脚本的访问都会被禁止。
2.cookie的概念：是一种存储在计算机浏览器目录中的文本文件。当用户浏览某个站点并注册账户，就会生成一个cookie文件用于记录登录信息。目前，大多数网站都会应用cookie技术，这既能给用户提供一个好的网络环境，又能方便收集访客信息。
3.攻击方法
1）攻击者视角
首先在公网服务器启动一个用于接受cookie的web服务，既可以使用python也可以使用apache
![image](https://github.com/Plonkloving/AnAn/assets/102906830/7e1ee8f7-035e-4056-8a11-b6e733797a4c)
btoa的作用是对获取的cookie进行base64编码

问题：如何判断网站的cookie是否有httponly限制？
可以抓包看看请求头cookie有没有在后面加上httponly字段
例如：security=impossible; PHPSESSID=d7k0dd7u5pkkhof1rv3q73hr84; security=impossible
这一个是dvwa持久型xss靶场的cookie头，这就没有显示httponly
//httpResp.addHeader("Set-Cookie", "JSESSIONID=" + sessionId
//	                            + "; Path=/admin;Secure; HttpOnly");

如果我已经获取到cookie，那我该如何利用？
首先重新打开一下网站，然后f12修改cookie，然后再去访问刚刚我发给用户的那个网站

所以这就要求了用户不能退出登录、并且我收集cookie的接收端必须布置在公网上

2）受害者视角


还有另外一种方法
利用现有的xss平台，xss平台是一个测试xss漏洞获取cookie的平台，xss可以做js能做的所有事情，八廓但不限于窃取cookie、后台删改文章、钓鱼、李勇xss漏洞进行传播、修改网页代码、网站重定向、获取用户信息等
攻击者视角：
首先准备一个xss平台用以接收cookie，这里用蓝莲花平台
伪造了一个真实存在的并且可以让用户信任的网站
因为如果我直接用python启动http服务的话，用户不一定会信任





网络钓鱼
钓鱼网站是指欺骗用户的虚假网站。钓鱼网站的页面与真实的页面一致，欺骗消费者或者窃取访问者的账号与密码。
钓鱼网站一般只有几个页面，和真实网站差别细微。钓鱼网站是互联网中最常碰见的一种诈骗方式，通常伪装成银行以及电子商务、窃取用户提交的银行账号、密码等私密信息的内容。
1）Flash钓鱼
伪造flash，比如伪造flash下载页面并且攻击者制造了一个类似的钓鱼软件
2）CS钓鱼
CS是一款团队作战渗透神器，是一种可以用来进行横向移动、数据窃取、鱼叉钓鱼。分为客户端和服务端。
首先需要开启服务端
chmod ./teamserver
./teamserver ip 密码
然后打开客户端
chmod +x ./CobaltStrike
./CobaltStrike
在打开客户端后输入服务端ip和连接密码即可使用
3）Beef神器



流量劫持
![image](https://github.com/Plonkloving/AnAn/assets/102906830/bb186a4b-61e2-41bc-b239-fe5ca05343b9)



xss防范
1.preg_replace()正则替换
语法：
mixed preg_replace( mixed $pattern , mixed $replacement , mixed $subject [, int $limit = -1 [, int &$count]]) 
这个代码是去用我指定格式去替换源代码
模式修饰符
i：忽略大小写
m：行首和行末就会匹配目标字符串中任意换行符之前或之后，另外，还分别匹配目标字符串的最开始和最末尾位置
s：模式中的点号元字符匹配所有字符，包含换行符。如果没有这个 修饰符，点号不匹配换行符
x：模式中的没有经过转义的或不在字符类中的空白数据字符总会被忽略，并且位于一个未转义的字符类外部的#字符和下一个换行符之间的字符也被忽略。
A：模式被强制为"锚定"模式，也就是说约束匹配使其仅从 目标字符串的开始位置搜索
D：模式中的元字符美元符号仅仅匹配目标字符串的末尾。如果这个修饰符 没有设置，当字符串以一个换行符结尾时， 美元符号还会匹配该换行符(但不会匹配之前的任何换行符)。 如果设置了修饰符m，这个修饰符被忽略
S：当一个模式需要多次使用的时候，为了得到匹配速度的提升，值得花费一些时间 对其进行一些额外的分析。如果设置了这个修饰符，这个额外的分析就会执行。
U：这个修饰符逆转了量词的"贪婪"模式。 使量词默认为非贪婪的，通过量词后紧跟? 的方式可以使其成为贪婪的。
X：这个修饰符打开了 PCRE 与 perl 不兼容的附件功能。模式中的任意反斜线后就 ingen 一个 没有特殊含义的字符都会导致一个错误，以此保留这些字符以保证向后兼容性。
J：内部选项设置(?J)修改本地的PCRE_DUPNAMES选项。允许子组重名， (译注：只能通过内部选项设置，外部的 /J 设置会产生错误。) 自 PHP 7.2.0 起，也能支持 J 修饰符。
u：模式和目标字符串都被认为是 UTF-8 的。 无效的目标字符串会导致 preg_* 函数什么都匹配不到； 无效的模式字符串会导致 E_WARNING 级别的错误。 5 字节和 6 字节的 UTF-8 字符序列以无效字符序列对待。


例如
<?php
$a = $_GET['a'];
echo preg_replace('/preg_replace/',$a,'This is Preg_replace');
?>
对于这个语法来说，是逐字匹配，就是从开头开始找，当能够找到完美符合指定目标字符串的时候就替换，不回头
注意这里的完美符合是指必须能够直接构成整体，这是不会一个一个区组单词
![image](https://github.com/Plonkloving/AnAn/assets/102906830/14b78e58-f255-4d24-a43d-96ff6cdf945b)




2.其他标签绕过
有时候会使用preg_match语法来实现匹配，比如
![image](https://github.com/Plonkloving/AnAn/assets/102906830/fa0e1ff8-647b-432d-a61d-155bb511f68b)

这些代码可以看看https://www.cnblogs.com/renhaoblog/p/12888130.html


3.url解码
这一般会先替换（转换成html实体），然后url解码
这种可以先url编码，这样程序就不会检测到有替换的字符串

4.过滤引号，过于大于号

5.CSP策略
CSP是内容安全策略
本质上：建立白名单，规定了浏览器只能执行特定来源的代码；就算发生xss，也不会加载来源不明的第三方脚本

6.http-only限制



如何判断xss？
输入框
评论
富文本编辑器
我输入的内容被完全显示，才能是没有xss

反射型虽然有输入框但一般都是在url里？a=这样的形式提交参数，所以要找到这个参数是什么
